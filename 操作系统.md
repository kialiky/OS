## 第一章 操作系统引论

### 一、系统的目标：

1）**有效性**：提高系统资源利用率；提高系统的吞吐量。

2）**方便性**：

3）可扩充性：

4）开放性：开放性是指操作系统能遵循世界标准规范，特别是遵循开放系统互联（OSI） 国际标准。凡遵循国际标准所开放的硬件和软件，均能彼此兼容，可方便的实现互连。

有效性和方便性是操作系统最重要两个目标。

### 二、操作系统的作用：

#### 1、 OS作为用户与计算机硬件系统之间的接口

OS 处于用户与计算机硬件系统之间，用户通过 OS 来使用计算机系统。

![image-20190405160210899](/Users/ss/Documents/操作系统/OS.png)

①**命令方式**：这是指由OS 提供了一组联机命令接口，以允许用户通过键盘输入有关命令来取得操作系统的服务，并控制用户程序的运行。

②**系统调用方式**：OS 提供了一组系统调用，用户可在自己的应用程序中通过相应的系统调用，来实现与操作系统的通信，并取得它的服务。

③**图形、窗口方式**：这是当前使用最为方便、最为广泛的接口，它允许用户通过屏幕上的窗口和图标来实现与操作系统的通信，并取得它的服务。

#### 2、OS作为计算机系统资源的管理者

系统资源分为四类：**处理器、存储器、I/O设备、信息（数据和程序）**。OS 的主要功能也正是针对这四类资源进行有效的管理，即：处理机管理，用于分配和控制处理机；存储器管理，主要负责内存的分配与回收；I/O 设备管理，负责 I/O设备的分配与操纵；文件管理，负责文件的存取、共享和保护。

当一个计算机系统同时供多个用户使用时，用户对系统中共享资源的需求（包括数量和时间）可能发生冲突，为了更好的管理好这些共享资源（包括硬件和信息）的使用，操作系统必须记录下各种资源的使用情况，对使用资源的请求进行授权，协调诸用户对共享资源的使用，避免发生冲突，并计算使用资源的费用等。

#### 3、OS实现了对计算机资源的抽象

对于一个完全无软件的计算机系统（即裸机），它向用户提供的是实际硬件接口（物理接口），用户必须对物理接口的实现细节有充分的了解，并利用机器指令进行编程，因此该物理机器必定是难以使用的。

**在裸机上铺设的 I/O软件隐藏了对 I/O 设备操作的具体细节，向上提供了一组抽象的 I/O 设备。**

![image-20190405160648317](/Users/ss/Documents/操作系统/I:O软件.png)

OS 是铺设在计算机硬件上的多层系统软件，它们不仅增强了系统的功能，而且还隐藏了对硬件操作的细节，由它们实现了对计算机硬件操作的多个层次的抽象。

### 三、OS的发展过程

无操作系统的计算机系统→单道批处理系统→多道批处理系统→分时系统→实时系统→微机操作系统

### 四、操作系统的基本特征：

并发、共享、虚拟、异步。

并发特征是操作系统最重要的特征，其他三个特征都是以并发特征为前提的。

#### 1、 并发性

1. 并行与并发

并行性是指**两个或多个事件在同一时刻发生**；并发性是指**两个或多个事件在同一时间间隔内发生**。

2. 引入进程

进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的。是一个能独立运行的活动实体。

通常的程序是静态实体，在多道程序系统中，它们是不能独立运行的，更不能和其它程序并发执行。在操作系统中引入进程的目的，就是为了使多个程序能并发执行。

引入进程事实上可以在内存中存放多个用户程序，分别为它们建立进程后，这些程序可以并发执行，亦即实现多道程序运行。这样能极大提高系统资源的利用率，增加系统的吞吐量。

3. 引入线程

通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源。在引入线程的 OS 中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位。

#### 2、 共享性

在操作系统环境下，共享 是指系统中的**资源可供内存中多个并发的进程功能使用**，相应地，把这种资源共同使用成为资源共享，或成为资源复用。

目前主要实现资源复用的方式有：

1）**互斥共享**方式

2）**同时访问**方式

#### 3、虚拟技术

操作系统中的所谓“虚拟”，是指通过某种技术把**一个物理实体变为若干个逻辑上的对应物**。物理实体是实的，即实际存在的，而后者是虚的，近视用户感受上的东西。相应的，用于实现虚拟的技术成为虚拟技术。在操作系统中利用了两种方式实现虚拟技术，即**时分复用技术和空分复用技术**。

1、时分复用技术

时分复用，亦即分时使用方式

1）虚拟处理机技术

2）虚拟设备技术

2、空分复用技术

1）虚拟磁盘技术

2）虚拟存储器技术

#### 4、异步性

**进程是以人们不可预知的速度向前推进**，此即进程的异步性。但只要在操作系统中配置有完善的进程同步机制，且运行环境相同，作业经多次运行都会获得完全相同的结果。因此，异步运行方式是允许的，而且是操作系统的一个重要特征。

### 五、操作系统的主要功能

操作系统的主要任务，是为多道程序的运行提供良好的运行环境，以保证多道程序能有条不紊的、高效的运行，并能最大限度的提高系统中各种资源的利用率和方便用户的使用。为实现上述任务，操作系统应具有以下功能：**处理机管理，存储器管理，设备管理和文件管理**。

#### 1、处理机管理功能

处理机管理的主要功能是**创建和撤销**进程，对诸进程的运行进行**协调**，实现进程之间的**信息交换**，以及按照一定的算法把处理及分配给进程。

##### 1、进程控制

进程控制的主要功能是为作业创建进程，撤销已结束的进程，以及控制进程在运行过程中的状态转换。

##### 2、进程同步

进程同步的主要任务是为多个进程的运行进行协调。有两种协调方式：

1）**进程互斥方式**：这是指诸进程在对临界资源进行访问时，应采用互斥方式；

2）**进程同步方式**：这是指在相互合作去完成功能任务的诸进程间，由同步机构对他们的执行次序加以协调。

##### 3、进程通信

在多道程序环境下，为了加速应用程序的运行，应在系统中建立多个进程，并且再为一个进程建立若干个线程，由这些进程(线程)相互合作去完成一个共同的任务。

##### 4、调度

1）作业调度

作业调度的基本任务是从后备队列中按照一定的算法，选择出若干个作业，为他们分配运行所需的资源。在将他们调入内存后，便分别为他们建立进程，使他们都成为可能获得处理机的就绪进程，并按照一定的算法将他们插入就绪队列。

2）进程调度

进程调度的任务是从进程的就绪队列中，按照一定的算法选出一个进程，把处理机分配给它，并为它设置运行现场，使进程投入执行。值得提出的是，在多线程OS中，通常是把线程作为独立运行和分配处理机的基本单位，为此，须把就绪线程排成一个队列，每次调度时，是从就绪线程队列中选出一个线程，把处理机分配给它。

#### 2、存储器管理功能

存储器的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。

##### 1、内存分配

内存分配的主要任务是为每道程序分配内存空间，使它们“各得其所”；提高存储器的利用率，以减少不可用的内存空间；允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。

为了实现内存分配，在内存分配的机制中应具有这样的结构功能：

1）内存分配数据结构。该结构用于记录内存空间的使用情况，作为内存分配的依据。

2）内存分配功能。系统按照一定的内存分配算法为用户程序分配内存空间。

3）内存回收功能。系统对用用户不再需要的内存，通过用户的释放请求去完成系统的回收功能。

##### 2、内存保护

内存保护的主要任务是确保每道用户程序都只在自己的内存空间内运行，彼此互不干扰；决不允许用户程序访问操作系统的程序和数据；也决不允许用户程序转移到非共享的其他用户程序中去执行。

##### 3、地址映射

##### 4、内存扩充

为了能在逻辑上扩充内存，系统必须具有内存扩充机制，用于实现下述各功能：

1）请求调入功能。

允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向OS发出请求，由OS从磁盘中将所需部分调入内存，以便继续运行。

2）置换功能。

若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内存。

#### 3、设备管理功能

完成用户进程提出的 I/O 请求；为用户进程分配所需的 I/O 设备；提高 I/O 设备和 CPU 的利用率；提高 I/O 速度；方便用户使用 I/O 设备。

设备管理应具有：缓冲管理，设备分配，设备处理以及虚拟设备等功能。

##### 1、缓冲管理：

##### 2、设备分配：

设备分配的基本任务是根据用户进程的 I/O 请求、系统的现有资源情况以及按某种设备的分配策略，为之分配其所需的设备。

##### 3、设备处理：

设备处理的基本任务是用于实现 CPU 和设备控制之间的通信。

##### 4、虚拟设备：

#### 4、文件管理功能

文件管理的主要任务是对用户文件和系统文件进行管理，以方便用户使用，并保证文件的安全性。

为此，文件管理应具有对文件存储空间的管理、目录管理、文件的读/写管理，以及文件的共享与保护等功能。

##### 1、文件存储空间的管理

为每个文件分配必要的外存空间，提高外存利用率，并能有助于提高文件系统的存、取速度。

##### 2、目录管理

为每个文件建立其目录项，并对众多的目录项加以有效的组织，以实现方便的按名存取，即用户只需提供文件名便可对该文件进行存取。

##### 3、文件的读/写管理和保护

1）文件的读、写管理

根据用户的请求，从外存中读取数据，或将数据写入外存。

2）文件保护

①防止未经核准的用户存取文件

②防止冒名顶替存取文件

③防止以不正确的方式使用文件

#### 5、操作系统与用户之间的接口

用户与操作系统的接口：

##### 1、用户接口

它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务。

1）联机用户接口

为联机用户提供，它由一组键盘操作命令及命令解释程序所组成。

2）脱机用户接口

为批处理作业的用户提供的，故也称批处理用户接口。该接口由一组作业控制语言（JCL）组成。批处理作业的用户不能直接与自己的作业交互作用，只能委托系统代替用户对作业进行干预和控制。这里的作业控制语言 JCL 便是把需要对作业进行的控制和干预事先写在作业说明书上，然后将作业和作业说明书一起提供给系统。

3）图形用户接口

图形用户接口采用了图形化的操作界面，用非常容易识别的各种图标将系统的各项功能、各种应用程序和文件，直观、逼真的表示出来。

##### 2、程序接口

是为用户程序在执行中访问系统资源而设置的，是用户程序取得操作系统服务的唯一途径。

### 六、 OS 结构设计

#### 1、传统的操作系统结构

##### 1、无结构操作系统

早起开发系统时，设计者只是把注意力放在功能的实现和获得高的效率上，缺乏首尾一致的设计思想，此时的 OS 是为数众多的一组过程的集合，每个过程可以任意的相互调用其他过程，致使操作系统内部既复杂又混乱，因此，这种 OS 是无结构的，也有人把它称为整体系统结构。

##### 2、模块化结构 OS

1）基本概念：该技术是基于“分解”和“模块化”原则来控制大型软件的复杂度。为使 OS 具有较清晰的结构，按其功能划分为若干个具有一定独立性和大小的模块；每个模块具有某方面的功能，并仔细规定好各模块间的接口。若子模块过大，可以再进一步进行细分。这种设计方法称为模块-接口法，由此构成的操作系统就是具有模块化结构的操作系统。如图1-6：

2）模块的独立性：如果再划分模块时，将模块划分的太小，虽然可以降低模块本身的复杂性，但会引起模块之间的联系过多，而会造成系统混乱；如果模块划分的过大，又会增加模块内部的复杂性，使内部的联系增加。因此在划分模块时，应在两者间进行权衡：

①内聚性：指模块内部各部分之间的紧密程度，内聚性越高，模块的独立性越强。

②耦合度：指模块间相互联系和相互影响的程度，耦合度越低、模块化的独立性越好。

3）模块接口法的优缺点：

①提高 OS 设计的正确性、可理解性和可维护性。

②增强 OS 的适应性。

③加速 OS 的开发过程。

模块化结构存在的问题：

①在OS 设计时，对各模块间的接口规定很难满足在模块完成后对接口的实际需求。

②在模块化结构设计中，各模块的设计齐头并进，无法寻找到一个可靠的决定顺序，造成各种无法决定的“无序性”，使设计人员很难做到“设计中的每一步决定都是建立在可靠地基础上”，故模块-接口法又被称为“无序模块法”。

##### 3、分层式结构 OS

1）基本概念：为了将模块―接口法中“决定顺序”的无序性变为有序性，引入了有序分层法。分层法的设计任务是，在目标系统An和裸机系统(又称宿主系统)A0之间，铺设若干个层次的软件A1、A2、A3、...、An-1，使An通过An-1、An-2、...、A2、A1层，最终能在A0上运行。在操作系统中，常采用自底向上法来铺设这些中间层。
自底向上的分层设计的基本原则是：每一步设计都是建立在可靠的基础上。为此规定，每一层仅能使用其底层所提供的功能和服务。

2）分层结构的主要优点：
①易保证系统的正确性。自上而下的设计方式，是所有的设计中的决定都是有序的，或者说是建立在较为可靠的基础上，这样比较容易保证整个系统的正确性。
②易扩充和易维护性。在系统中增加、修改或替换一个层次中的模块或整个层次，只要不改变相应层次间的接口，就不会影响其它层次，这必将使系统维护和扩充变得更加容易。

分层结构的主要缺点：系统效率降低了。由于层次结构是分层单向依赖的，因此必须在相邻层之间都要建立层次间的通信机制，OS 每执行一个功能，通常要自上而下地穿越多个层次，这无疑会增加系统的通信开销，从而导致系统效率的降低。

#### 2、客户/服务器模式

客户/服务器（Client/Server）模式可简称为 C/S 模式，在20世纪90年代已风靡全球，不论是LAN，还是企业网，以及Internet所提供的多种服务，都广泛采用了客户/服务器模式。

1、客户/服务器模式的组成

客户/服务器系统主要由客户机、服务器和网络系统三个部分组成。

1）客户机：通常在一个LAN网络上连接有多台网络工作站(简称客户机)，每台客户机都是一个自主计算机，具有一定的处理能力，客户进程在其上运行，平时它处理一些本地业务，也可发送一个消息给服务器，以请求某项服务。

2）服务器：通常是一台规模较大的机器，在其上驻留有网络文件系统或数据库系统等，它应能为网上所有的用户提供一种或多种服务。

3）网络系统：用于连接所有客户机和服务器，实现它们之间通信和网络资源共享的系统。

2、客户/服务器之间的交互

1）客户发送请求消息

2）服务器接收消息

3）服务器回送消息

4）客户机接收消息

3、客户/服务器模式的优点

1）数据的分布处理和存储

2）便于集中管理

3）灵活性和可扩充性

4）易于改编的应用软件

### 1.5.4 微内核 OS 结构

1、微内核操作系统的基本概念

1）**足够小的内核**
在微内核操作系统中，内核是精心设计的、能实现现代 OS 最基本的核心功能部分。微内核并非是一个完整的 OS，而只是操作系统中最基本的部分，它通常用于：①实现与硬件紧密相关的处理；②实现一些较基本的功能；③负责客户和服务器之间的通信。

2）**基于客户**/**服务器模式**
 将操作系统中最基本的部件放入内核中，而把操作系统的绝大部分功能都放在微内核外面的一组服务器（进程）中实现。例如用于提供对进程（线程）进行管理的进程（线程）服务器，提供虚拟存储器管理功能的虚拟存储器服务器，提供 I/O 设备管理的 I/O 设备管理服务器等。运行在用户态，客户与服务器之间是借助微内核提供的消息传递机制来实现信息交互的。如图1-10：在单机环境下的客户/服务器模式

![img](https:////upload-images.jianshu.io/upload_images/1711514-ccb0ecd3908b41fd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000)



3）**应用“机制与策略分离”原理**
所谓机制，是指实现某一功能的具体执行机构。而策略，则是在机制的基础上，借助于某些参数和算法来实现该功能的优化，或达到不同的功能目标。

4）**采用面向对象技术**
操作系统是一个及其复杂的大型软件系统，可以基于面向对象技术中的“抽象”和“隐蔽”原则控制系统的复杂性，再进一步利用“对象”、“封装”和“继承”等概念来确保操作系统的“正确性”、“可靠性”、“易修改性”、“易扩展性”等，并提高操作系统的设计速度。

## 第二章 进程管理

### 一、进程的基本概念

在传统的操作系统中，程序并不能独立运行，作为资源分配和独立运行的基本单位都是进程。

#### 1、程序的顺序执行及其特征

##### 1. 程序的顺序执行

把一个应用程序分成若干个程序段，在各程序段之间，必须按照某种先后次序顺序执行，仅当前一操作（程序段）执行完后，才能执行后及操作。

##### 2. 程序顺序执行时的特征

1）**顺序性**
处理机的操作严格按照程序所规定的顺序执行，即每一操作必须在上一个操作结束之后开始

2）**封闭性**
程序是在封闭环境下执行的，即程序运行时独占全机资源，资源的状态（除初始状态外）只有本程序才能改变它。程序一旦执行，其执行结果不受外界因素影响。

3）**可再现性**
只要程序执行是的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿的执行，还是断续执行，都将获得相同的结果

#### 2、前趋图

前趋图（Precedence Graph）是一个有向无循环图，记为DAG（Directed Acyclic Graph），用于描述进程之间之行的前后关系。

#### 3、程序的并发执行及其特征

##### 1. 程序的并发执行

输入程序在输入第一个程序后，在计算程序对该程序进行计算的同时，可由输入程序再输入第二个程序，从而使第一个程序的计算操作可与第二个程序的输入操作并发执行。一般来说，输入程序在输入第 i+1个程序时，计算程序可能正在对第 i 个程序进行计算，而答应程序正在打印第 i-1个程序的计算结果。

##### 2. 程序并发执行时的特征

1）**间断性**: 程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间，形成了相互制约的关系。相互制约将导致并发程序具有“执行——暂停——执行”这种间断性的活动规律。

2）**失去封闭性**: 程序在并发执行时，是多个程序共享系统中的各种资源。因而这些资源的状态将有多个程序来改变，致使程序的运行失去了封闭性。这样，某程序在执行时，必然会受到其他程序的影响。

3）**不可再现性**: 程序在并发执行时，失去了封闭性，计算结果已与并发程序的执行速度有关，从而使程序的执行失去了可再现性，亦即，程序经过多次执行后，虽然它们执行时的环境和初始条件相同，但得到的结果却各不相同。

#### 4、进程的特征与状态

##### 1. 进程的特征和定义

1）**结构特征**
通常的程序是不能并发执行的。为使程序（含数据）能独立运行，应为之配置一进程**控制块**，即 **PCB（Process Control Block）**：而由程序段、相关的数据段和 PCB 三部分便构成了**进程实体**。在早期的 UNIX 版本中，把这三部分总称为“进程映像”。在许多情况下所说的进程，实际上是指进程实体，如，所谓创建进程，实质上是创建进程实体中的 PCB；而撤销进程，实质上是撤销进程的 PCB。

2）**动态性**
进程的实质是进程实体的一次执行过程，因此，动态性是进程的最基本特征。进程实体有一定的生命期，而程序则只是一组有序指令的集合，并存放区某种介质上，其本身并不具有运动的含义，因而是静态的。

3）**并发性**
并发性是指多个进程实体同存于内存中，且能在一段时间内同时运行。并发性是进程的重要特征，同时也成为 OS 的重要特征。引入进程的目的也正是为了使其进程实体能和其它进程实体并发执行；而程序（没有建立 PCB）是不能进行并发执行的。

4）**独立性**
在传统的 OS 中，独立性是指进程实体是一个能独立运行、独立分配资源和独立接受调度的基本单位。凡未建立 PCB 的程序都不能作为一个独立的单位参与运行

5）**异步性**
这是指进程按各自独立、不可预知的速度向前推进，或说进程实体按异步方式运行。
①进程是程序的一次执行
②进程是一个程序及其数据在处理机上顺序执行时所发生的活动
③进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位

在引入了进程实体的概念后，我们可以把传统的 OS 中的进程定义为：“**进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位**”。

##### 2. 进程的三种基本状态

1）**就绪状态**
当进程已分配到除 CPU 以外的所有必要资源后，只要再获得 CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。

2）**执行状态**
进程已获得 CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态；在多处理机系统中，则有多个进程处于执行状态。

3）**阻塞状态**
正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，亦即进程的执行收到阻塞，把这种暂停状态成为阻塞状态，有时也称为等待状态或封锁状态。
致使进程阻塞的典型事件有：请求 I/O，申请缓冲空间等。

![image-20190405164646013](/Users/ss/Documents/操作系统/进程状态.png)

##### 3.**挂起状态**

1）引入挂起状态的原因
①终端用户的请求
②父进程请求
③负荷调节的需要
④操作系统的需要

2）进程状态的转换
①活动就绪→静止就绪
②活动阻塞→静止阻塞
③静止就绪→活动就绪
④静止阻塞→活动阻塞

![image-20190405164824673](/Users/ss/Documents/操作系统/含挂起的进程状态.png)

##### 4. 创建状态和终止状态

1）创建状态
创建一个进程一般要通过两个步骤：首先，为一个新进程创建 PCB，并填写必要的管理信息；其次，把该进程转入就绪状态并插入就绪队列中，当一个新进程被创建时，系统已为其分配了 PCB，填写了进程标识等信息，但由于该进程所必须的资源或其他信息，如主存资源尚未分配时等，一般而言，此时的进程已拥有了自己的 PCB，但进程自身还未进入主存，即创建工作尚未完成，进程还不能被调度运行，其所处的状态就是创建状态。
引入创建状态，是为了保证进程的调度必须在创建工作完成后进行，以确保对进程控制块操作的完整性。同时，创建状态的引入，也增加了管理的灵活性，操作系统可以根据系统性能或主存容量的限制，推迟创建状态进程的提交。对于处于创建状态的进程，获得了其所必须的资源，以及对其 PCB 初始化工作完成后，进程状态便可由创建状态转入就绪状态。

2）终止状态
进程的终止也要通过两个步骤：首先等待操作系统进行善后处理，然后将其 PCB 清零，并将 PCB 空间返还系统。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入终止状态的进程以后不能再执行，但在操作系统中依然保留一个记录，其中保存状态码和一些计时统计数据，供其他进程收集。一旦其他进程完成了对终止状态进程的信息提取之后，操作系统将删除该进程。

![image-20190405165343092](/Users/ss/Documents/操作系统/含创建终止的进程状态.png)

如图2-8所示，引进创建和终止状态后，在进程状态转换时，相比较2-7所示的进程五状态而言，需要增加考虑下面的几种情况。

①NULL→创建：一个新进程产生时，该进程处于创建状态。

②创建→活动就绪：在当前系统的性能和内存的容量均允许的情况下，完成对进程创建的必要操作后，相应的系统进程将进程的状态转换为活动就绪状态。

③创建→静止就绪：考虑到系统当前资源状况和性能要求，并不分配给新建进程所需资源，主要是主存资源，相应的系统进程将进程状态转换为静止就绪状态，对换到外存，不再参与调度，此时进程创建工作尚未完成。

④执行→终止：当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，进程即进入终止状态。

##### 5. 进程控制块

为了描述和控制进程的运行，系统为每个进程定义了一个数据结构——进程控制块 PCB（Process Control Block），它是进程实体的一部分，是操作系统中最重要的记录数据结构。PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。

进程控制块的作用是使一个在多道程序环境下不能独立运行的程序（含数据），成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程。或者说，**OS 是根据 PCB 来对并发执行的进程进行控制和管理的**。

在进程的整个生命期中，系统总是通过 PCB 对进程进行控制的，亦即，系统时根据进程的 PCB 而不是任何别的什么而感知到该进程的存在的，所以说，PCB 是进程存在的唯一标志。

#### 5、进程创建

1、给新进程分配一个唯一的进程标识符

2、给进程分配空间

3、初始化进程控制块

4、设置正确的连接

5、创建或扩充其他数据结构

### 二、 线程

#### 1、线程基本概念

一个线程中可以有多个线程，是独立调度的基本单位。同一个进程中的多个线程之间可以并发执行，它们共享进程资源。

#### 2、进程和线程区别

① **拥有资源**：进程是**资源**分配的基本单位，但是线程不拥有资源，线程可以访问率属进程的资源。

② **调度**：线程是**独立调度**的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

③ **系统开销**：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，因此操作系统所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置。而线程切换时只需保存和设置少量寄存器内容，开销很小。此外，由于同一进程内的多个线程共享进程的地址空间，因此，这些线程之间的同步与通信非常容易实现，甚至无需操作系统的干预。

④ **通信方面**：进程间通信 (IPC) 需要进程同步和互斥手段的辅助，以保证数据的一致性，而线程间可以通过直接读/写进程数据段（如全局变量）来进行通信。

举例：QQ 和 浏览器是两个进程，浏览器进程里面有很多线程，例如 http 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 http 请求时，浏览器还可以响应用户的其它事件。

#### 3、线程的实现方式

1. **用户级线程**（也可看作协程）：进程内的线程切换不用切换到内核进行， 内核并没有感知进程内的线程存在， 所以即使多线程并不能利用多核来进行操作。一个线程如果调用了阻塞系统调用， 那整个进程都会被阻塞。
2. **内核级线程**（通常所说的线程）：也即内核管理的所有线程， 内核头既包含进程表， 也包含线程表。多线程可以利用到多核，多核下微观和宏观下都能做到并行。
3. **混合模式**： 内核线程可以在用户空间完成创建，应用的多个用户级线程可以被映射到内核线程中，提高并发效率。

### 三、进程间通信

进程通信可以看成是不同进程间的线程通信，对于同一个进程内线程的通信方式，主要使用信号量、条件变量等同步机制。

#### 1、管道pipe

管道是**单向的、先进先出的、无结构的、固定大小的字节流**，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。

管道提供了简单的流控制机制，进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

管道有三种：

① 普通管道：有两个限制：一是只支持半双工通信方式，即只能单向传输；二是只能在父子进程之间使用；

② 流管道：去除第一个限制，支持双向传输；

③ 命名管道：去除第二个限制，可以在不相关进程之间进行通信。

#### 2、共享内存

共享内存就是映射一段能被其它进程所访问的内存，这段共享内存由一个进程创建，但**多个进程都可以访问**。共享内存是**最快**的 IPC 方式，它是针对其它进程间通信方式运行效率低而专门设计的。它往往与其它通信机制（如信号量）配合使用，来实现进程间的同步和通信。

#### 3、消息队列

消息的链表， 存放于内核并由队列标识符标识；克服了缓冲区大小受限，信号信息有限，管道无格式字节流等缺点。

#### 4、信号

用于通知某个进程某个事件已经发生，可触发进程已注册的处理函数。

#### 5、信号量

一种计数器，用来控制多个进程对共享资源的访问， 通常作为一种锁机制， 常应用于进程间或进程内多个线程的同步。

#### 6、Socket

通过套接字通信，也可用于不同host之间的进程见通信。

### 四、进程同步

#### 1、临界区（CriticalSection）（进程内线程同步）

一次只能被一个进程所占用的资源为**临界资源**；进程内访问临界资源的代码就是**临界区**。为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

#### 2、 同步与互斥

同步指多个进程按**一定顺序**执行；互斥指多个进程在**同一时刻只有一个进程能进入临界区**。同步是在对临界区互斥访问的基础上，通过其它机制来实现有序访问的。

#### 2、事件

基于事件机制， 一个进程/线程主动唤醒另一个进程/线程；比如监听通信端口A。

#### 3、互斥量（Mutex）

类似临界区，但是能在进程间使用。Futex由一块能被多个进程共享的内存空间(对齐后的整型变量)组成, 保存在用户空间的共享内存中，通过原子操作进行操作。操作基本在用户空间内进行(需要仲裁时使用系统内核调用), 减少了系统调用次数， 提供系统性能。

原语：为完成某些特定功能而编制的一段系统程序，它在执行时不可分割、不可中断。原语操作也称为“**原子操作**”。

#### 4、信号量(Semphore)

信号量建立在原子操作上，使用信号量可以用来限制共享资源的线程数目。

**信号量（Samaphore）**是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **P** : 如果信号量大于 0 ，执行 - 1 操作；如果信号量等于 0，将进程睡眠，等待信号量大于 0；
- **V**：对信号量执行 + 1 操作，并且唤醒睡眠的进程，让进程完成 P 操作。

P 和 V 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了**互斥量（Mutex）**，0 表示临界区已经加锁，1 表示临界区解锁。

```c
typedef int samaphore;
samaphore mutex = 1;
void P1() {
    P(mutex);
    // 临界区
    V(mutex);
}

void P2() {
    P(mutex);
    // 临界区
    V(mutex);
}
```

#### 5、经典进程同步问题

##### **1. 生产者-消费者问题**

使用一个互斥量 mutex 来对临界资源进行访问；empty 记录空缓冲区的数量，full 记录满缓冲区的数量。

注意，必须**先执行 P 操作再用互斥量对临界区加锁**，否则会出现死锁。如果都先对临界区加锁，然后再执行 P 操作，考虑这种情况：生产者对临界区加锁后，执行 P(empty) 操作，发现 empty = 0，此时生成者睡眠。消费者此时不能进入临界区，因为生产者对临界区加锁了，也就无法对执行 V(empty) 操作，那么生产者和消费者就会一直等待下去。

```c
#define N 100
typedef int samaphore;
samaphore mutex = 1;  //互斥信号量
samaphore empty = N;  //可供使用的缓冲区数
samaphore full = 0;   //方有产品的缓冲区数

//生产者进程
void producer() {
    while(TRUE){
        int item = produce_item;
        P(empty);
        P(mutex);
        insert_item(item);  //产品送往buffer
        V(mutex);
        V(full);
    }
}

//消费者进程
void consumer() {
    while(TRUE){
        P(full);
        P(mutex);
        int item = remove_item(item);  //从buffer取出产品
        V(mutex);
        V(empty);
        consume_item(item);
    }
}
```

##### 2. 读者-写者问题

有读者和写者两组并发进程，共享一个文件，当两个或以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：①允许多个读者可以同时对文件执行读操作；②只允许一个写者往文件中写信息；③任一写者在完成写操作之前不允许其他读者或写者工作；④写者执行写操作前，应让已有的读者和写者全部退出。

首先设置信号量count为计数器，用来记录当前读者数量，初值为0; 设置mutex为互斥信号量，用于保护更新count变量时的互斥；设置互斥信号量rw用于保证读者和写者的互斥访问。

1) **读进程优先**: 也就是说，当存在读进程时，写操作将被延迟，并且只要有一个读进程活跃，随后而来的读进程都将被允许访问文件。这样的方式下，会导致写进程可能长时间等待，且存在写进程“饿死”的情况。

```c
int count=0; //用于记录当前的读者数量
semaphore mutex=1; //用于保护更新count变量时的互斥
semaphore rw=1; //用于保证读者和写者互斥地访问文件

writer () { //写者进程
    while (1){
        P(rw); // 互斥访问共享文件
        Writing; //写入
        V(rw) ; //释放共享文件
    }
}

reader () { // 读者进程
    while(1){
        P (mutex) ; //互斥访问count变量
        if (count==0) //当第一个读进程读共享文件时
            P(rw); //阻止写进程写
        count++; //读者计数器加1
        V (mutex) ; //释放互斥变量count
        reading; //读取
        P (mutex) ; //互斥访问count变量
        count--; //读者计数器减1
        if (count==0) //当最后一个读进程读完共享文件
            V(rw) ; //允许写进程写
        V (mutex) ; //释放互斥变量 count
    }
}
```

2) **写进程优先**: 即当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等待到已在共享文件的读进程执行完毕则立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。为此，增加一个信号量并且在上面的程序中 writer()和reader()函数中各增加一对PV操作，就可以得到写进程优先的解决程序。

```c
int count = 0; //用于记录当前的读者数量
semaphore mutex = 1; //用于保护更新count变量时的互斥
semaphore rw=1; //用于保证读者和写者互斥地访问文件
semaphore w=1; //用于实现“写优先”

writer(){
    while(1){
        P(w); //在无写进程请求时进入
        P(rw); //互斥访问共享文件
        writing; //写入
        V(rw); // 释放共享文件
        V(w) ; //恢复对共享支件的访问
    }
}

reader () { //读者进程
    while (1){
        P (w) ; // 在无写进程请求时进入
        P (mutex); // 互斥访问count变量
        if (count==0) //当第一个读进程读共享文件时
            P(rw); //阻止写进程写
        count++; //读者计数器加1
        V (mutex) ; //释放互斥变量count
        V(w); //恢复对共享文件的访问
        reading; //读取
        P (mutex) ; //互斥访问count变量
        count--; //读者计数器减1
        if (count==0) //当最后一个读进程读完共享文件
            V(rw); //允许写进程写
        V (mutex); //释放互斥变量count
    }
}
```

##### 3. 哲学家进餐问题

1) 关系分析。5名哲学家与左右邻居对其中间筷子的访问是互斥关系。

2) 整理思路。显然这里有五个进程。本题的关键是如何让一个哲学家拿到左右两个筷子而不造成死锁或者饥饿现象。那么解决方法有两个，一个是让他们同时拿两个筷子；二是对每个哲学家的动作制定规则，避免饥饿或者死锁现象的发生。

```c
semaphore chopstick[5] = {1,1,1,1,1};
while(true)
{
	/*当哲学家饥饿时，总是先拿左边的筷子，再拿右边的筷子*/
	P(chopstick[i]);
	P(chopstick[(i+1)%5]);// 吃饭
 
/*当哲学家进餐完成后，总是先放下左边的筷子，再放下右边的筷子*/
    V(chopstick[i]);
    V(chopstick[(i+1)%5]);
}
```

上述的代码可以保证不会有两个相邻的哲学家同时进餐，但却可能引起**死锁**的情况。

假如五位哲学家同时饥饿而都拿起的左边的筷子，就会使五个信号量chopstick都为0，当他们试图去拿右手边的筷子时，都将无筷子而陷入无限期的等待。

**为避免死锁，可以使用以下三种策略：**

**策略一**原理：至多只允许四个哲学家同时进餐，以保证至少有一个哲学家能够进餐，最终总会释放出他所使用过的两支筷子，从而可使更多的哲学家进餐。定义信号量count，只允许4个哲学家同时进餐，这样就能保证至少有一个哲学家可以就餐。

```c
semaphore chopstick[5]={1,1,1,1,1};
semaphore count=4; // 设置一个count，最多有四个哲学家可以进来
void philosopher(int i)
{
	while(true)
	{
		think();
		P(count); //请求进入房间进餐 当count为0时 不能允许哲学家再进来了
		P(chopstick[i]); //请求左手边的筷子
		P(chopstick[(i+1)%5]); //请求右手边的筷子
		eat();
		V(chopstick[i]); //释放左手边的筷子
		V(chopstick[(i+1)%5]); //释放右手边的筷子
		V(count); //退出房间释放信号量
	}
}
```

**策略二**原理：仅当哲学家的左右两支筷子都可用时，才允许他拿起筷子进餐。可以利用AND 型信号量机制实现，也可以利用信号量的保护机制实现。利用信号量的保护机制实现的思想是通过记录型信号量mutex对取左侧和右侧筷子的操作进行保护，使之成为一个原子操作，这样可以防止死锁的出现。描述如下：

```c
semaphore mutex = 1; // 这个过程需要判断两根筷子是否可用，并保护起来
semaphore chopstick[5]={1,1,1,1,1};
void philosopher(int i)
{
	while(true)
	{
		/* 这个过程中可能只能由一个人在吃饭 */
		think();
		P(mutex); // 保护信号量
		P(chopstick[(i+1)%5]); // 请求右手边的筷子
		P(chopstick[i]); // 请求左手边的筷子
		V(mutex); // 释放保护信号量
		eat();
		V(chopstick[(i+1)%5]); // 释放右手边的筷子
		V(chopstick[i]); // 释放左手边的筷子
	}
}
```

**策略三**原理：规定奇数号的哲学家先拿起他左边的筷子，然后再去拿他右边的筷子；而偶数号的哲学家则先拿起他右边的筷子，然后再去拿他左边的筷子。按此规定，将是1、2号哲学家竞争1号筷子，3、4号哲学家竞争3号筷子。即五个哲学家都竞争奇数号筷子，获得后，再去竞争偶数号筷子，最后总会有一个哲学家能获得两支筷子而进餐。

```c
semaphore chopstick[5]={1,1,1,1,1};
void philosopher(int i)
{
	while(true)
	{
		think();
		if(i%2 == 0) //偶数哲学家，先右后左。
		{
			P (chopstick[(i + 1)%5]) ;
			P (chopstick[i]) ;
			eat();
			V (chopstick[(i + 1)%5]) ;
			V (chopstick[i]) ;
		}
		else //奇数哲学家，先左后右。
		{
			P (chopstick[i]) ;
			P (chopstick[(i + 1)%5]) ;
			eat();
			V (chopstick[i]) ;
			V (chopstick[(i + 1)%5]) ;
		}
	}
}
```

##### 4. 打瞌睡的理发师问题

最常见的解决方案就是使用三个信号量（Semaphore）：一个给顾客信号量，一个理发师信号量（看他自己是不是闲着），第三个是互斥信号量（Mutual exclusion，缩写成mutex）。一位顾客来了，他想拿到互斥信号量，他就等着直到拿到为止。顾客拿到互斥信号量后，会去查看是否有空着的椅子（可能是等候的椅子，也可能是理发时坐的那张椅子）。 

如果没有一张是空着的，他就走了。如果他找到了一张椅子，就会让空椅子的数量减少一张，这位顾客接下来就使用自己的信号量叫醒理发师。这样，互斥信号标就释放出来供其他顾客或理发师使用。如果理发师在忙，这位顾客就会等。理发师就会进入了一个永久的等候循环，等着被在等候的顾客唤醒。一旦他醒过来，他会给所有在等候的顾客发信号，让他们依次理发。

```c
wait=0//顾客信号量 
barber=0//理发师信号量
custNum=0 //当前顾客数量
mutex=1 //互斥量

//理发师操作：
void Barber(void){
	while(1){
		P(wait);    //唤醒等待的一位顾客
        P(mutex);  //顾客被唤醒，准备理发，没有顾客，则睡觉
        custNum--;    //当前店里顾客数减1
        V(barber);   //有顾客来了，醒来理发
        V(mettux):   //释放互斥信号量
    }
}

//顾客操作：
void Customer(void){
    while(1){
        P(mutex);    //顾客想要理发
        if(custNum<N){   //店里人没有满
            custNum++；
            V(wait);     //理发师睡觉的话，唤醒他理发
            V(mutex);    //释放互斥量，理发这一动作成功
            P(baber);    //理发师进行理发操作
        }
        else{
            V(metux);    //释放互斥量，打消进店理发的举动
        }
    }
}
```

#### 6、管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码中的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;
    
    procedure insert();
    begin
    
    end;
    
    procedure remove();
    begin
    
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，必须将进程阻塞，否者其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来让另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

**使用管程实现生成者-消费者问题**

```pascal
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 ten signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 第三章 死锁

### 一、死锁概念

多个进程在运行过程中因争夺资源而造成的一种僵局。

**饥饿**：所需资源总是被被的进程占有或抢占，得不到完成工作的机会。

**活锁**：多个进程在运行工程中因相互谦让而造成的一种僵局。

#### 1、死锁的条件

1. **互斥**：临界资源的互斥访问
2. **占有且等待**：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不可抢占**：进程没有完成则不是放占有的资源
4. **环路等待**：发生死锁指必然存在一个资源环形链。

### 二、死锁的处理方法

#### 1、 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。这种策略不可取。

#### 2.、死锁预防

在程序运行之前预防发生死锁。

##### 2.1 破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

##### 2.2 破坏占有且等待条件

**预分资源策略**：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

**“空手”申请资源策略**：每个进程在它不占有资源的时候才可以申请资源。

##### 2.3 破坏不可抢占条件

##### 2.4 破坏环路等待

**资源有序分配**：给资源统一编号，进程只能按编号顺序来请求资源。

#### 3、 死锁避免

在程序运行时避免发生死锁。

##### 3.1 安全状态

是指系统能够找到一个进程顺序（P1、P2……Pn），来为每个进程Pi分配所需资源，知道满足每个进程的最大需求，是每个进程能够顺利完成，则P1、P2……Pn即为安全状态。

##### 3.2 单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

##### 3.3 多个资源的银行家算法

1）可利用资源向量Available
是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果Available[j]=K，则表示系统中现有Rj类资源K个。
2）最大需求矩阵Max
这是一个n×m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。
3）分配矩阵Allocation
这也是一个n×m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的 数目为K。
4）需求矩阵Need

这也是一个n×m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，则表示进程i还需要Rj类资源K个，方能完成其任务。

下面是三者之间的关系:

Need[i,j]=Max[i,j]-Allocation[i,j]

银行家算法:

设Request(i)是进程Pi的请求向量，如果Request(i)[j]=k，表示进程Pi需要K个R(j)类型的资源。当Pi发现资源请求后系统将进行下列步骤

(1)如果Request(i)[j] <= Need[i,j],边转向步骤2),否则认为出错，因为它所请求的资源数已超过它所宣布的最大值。

(2)如果Request(i)[j] <= Available[i,j]，便转向步骤3)，否则，表示尚无足够资源，Pi需等待。

(3)系统试探着把资源分配给进程Pi，并需要修改下面数据结构中的数值；

Available[j] = Available[j] - Request(i)[j];

Allocation[i,j] = Allocation[i,j] + Request(i)[j];

Need[i,j] = Need[i,j] - Request(i)[j];

![屏幕快照 2019-04-06 下午12.34.38](/Users/ss/Documents/操作系统/银行家.png)

**从图中数据我们可以利用银行家算法的四个数据结构，来描述当前的系统状态**

![屏幕快照 2019-04-06 下午12.35.38](/Users/ss/Documents/操作系统/银行1.png)

因为系统资源R=（17,5,20）而系统分配给这几个线程的资源为Allocation=(15,2,17) 则可以求出Available=（2,3,3）

(1)在T0时刻，由于Availabel大于等于Need中 P5 所在行的向量，因此Availabel能满足 P5 的运行，在 P5 运行后，系统的状态变更为如下图所示:

![image-20190406123733750](/Users/ss/Documents/操作系统/银行2.png)

**因此，在T0时刻，存在安全序列：P5，P4，P3，P2，P1（并不唯一）**

(2)P2请求资源，P2发出请求向量Request(i)(0,3,4),系统根据银行家算法进行检查;
 ① P2 申请资源Reuqest(i)（0,3,4）<=Need中 P2 所在行向量Need(i)（1,3,4）

 ② P2 申请资源Reuqest(i)（0,3,4）>=可以利用资源向量Availabel（2,3,3），所以，该申请不给于分配

(3)P4请求资源，P4发出请求向量Request(i)(2,0,1),系统根据银行家算法进行检查;

 ①Reuqest(i)（2,0,1）<= Need(i)（2,2,1）

 ② Reuqest(i)（2,0,1 <= Availabel（2,3,3）

 ③对 P4 的申请（2,0,1）进行预分配后，系统的状态为：

![image-20190406123800394](/Users/ss/Documents/操作系统/银行3.png)

可利用资源向量Availabel=（0,3,2），大于Need中 P4 所在行的向量（0,2,0），因此可以满足 P4 的运行。P4 运行结束后，系统的状态变为：

**同理依次推导，可计算出存在安全序列P4，P5，P3，P2，P1(并不唯一）**

(4)P1请求资源，P1发出请求向量Request(i)(0,2,0),系统根据银行家算法进行检查;

 ①Request(i)(0,2,0)<= Need(i)（3,4,7）

 ② Request(i)(0,2,0)<= Availabel（2,3,3）

 ③对 P1 的申请（0,2,0）进行预分配后，系统的状态为：

![image-20190406123930679](/Users/ss/Documents/操作系统/银行5.png)

由于Availabel不大于等于 P1 到 P5 任一进程在Need中的需求向量，因此系统进行预分配后

处于不安全状态，所以对于 P1 申请资源（0,2,0）不给予分配。

注意:因为(4)是建立在第(3)问的基础上的所以Available=（0,3,2）-（0,2,0）=（0,1,2）

#### 4、死锁检测与死锁恢复

不试图组织死锁，而是当检测到死锁发生时，采取措施进行恢复。

##### 4.1 死锁检测算法

死锁检测的基本思想是，如果一个进程所请求的资源能够被满足，那么就让它执行，释放它拥有的所有资源，然后让其它能满足条件的进程执行。

##### 4.2 死锁恢复

- 利用抢占恢复
- 回退执行
- 杀死进程

## 第四章 调度

批量型作业通常需要经历作业调度（高级调度或长程调度）和进程调度（低级调度和短程调度）两个过程后方能获得处理机。

先了解两个概念：

- 周转时间： 从开始申请执行任务，到执行任务完成 
- 响应时间： 从开始申请执行任务，到开始执行任务

### 一、调度层次

1) **高级调度**（作业调度或长期调度）：把外存上处于后备队列中的那些作业调入内存。

2) **低级调度**（进程调度或短期调度）：它决定就绪队列中的哪个进程将获得处理机，然后由分派程序执行把处理机分配给该进程的操作。对象是进程。功能是：保存处理机现场信息（PCB）；按某种算法选取进程；把处理器分配给进程。方式分为非抢占方式和抢占方式。

3) **中级调度**（中期调度）：内存中不能有太多的进程，把进程从内存移到外存，当内存有足够空间时，再将合适的进程换入内存，等待进程调度。目的是提高内存利用率和系统吞吐量。

### 二、调度算法

批处理系统中的调度

#### 1、 先来先服务（FCFS）

first-come first-serverd。调度最先进入就绪队列的作业。

**有利于长作业，但不利于短作业**，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。（平均周转时间可能会很长 ）

#### 2、短作业优先（SJF）

shortest job first。调度估计运行时间最短的作业。

**长作业有可能会饿死**，处于一直等待短作业执行完毕的状态。如果一直有短作业到来，那么长作业永远得不到调度。（周转时间短，但是响应时间长 ）

#### 3、最短剩余时间优先（SRTF）

Shortest Remaining Time First。调度剩余运行时间最短的作业。

#### 4、优先级调度算法

又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。

根据新的更高优先级进程能否抢占正在执行的进程，可将该调度算法分为：

- **非剥夺式优先级调度算法**。当某一个进程正在处理机上运行时，即使有某个更为重要或紧迫的进程进入就绪队列，仍然让正在运行的进程继续运行，直到由于其自身的原因而主动让出处理机时（任务完成或等待事件），才把处理机分配给更为重要或紧迫的进程。
- **剥夺式优先级调度算法**。当一个进程正在处理机上运行时，若有某个更为重要或紧迫的进程进入就绪队列，则立即暂停正在运行的进程，将处理机分配给更重要或紧迫的进程。

而根据进程创建后其优先级是否可以改变，可以将进程优先级分为以下两种：

- **静态优先级**。优先级是在创建进程时确定的，且在进程的整个运行期间保持不变。确定静态优先级的主要依据有进程类型、进程对资源的要求、用户要求。
- **动态优先级**。在进程运行过程中，根据进程情况的变化动态调整优先级。动态调整优先级的主要依据为进程占有CPU时间的长短、就绪进程等待CPU时间的长短。

#### **5、高响应比算法（HRRF）**

Highest Response Ratio First。高响应比优先调度算法主要用于作业调度，该算法是对FCFS调度算法和SJF调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。

**响应比=(等待时间+要求服务时间)/要求服务时间；**

#### 6、时间片轮转调度（RR）

Round-Robin。按到达的先后对进程放入队列中，然后给队首进程分配CPU时间片，时间片用完之后计时器发出中断，暂停当前进程并将其放到队列尾部，循环 ;（响应时间可以得到保证）

在时间片轮转调度算法中，时间片的大小对系统性能的影响很大。如果时间片足够大，以至于所有进程都能在一个时间片内执行完毕，则时间片轮转调度算法就退化为先来先服务调度算法。如果时间片很小，那么处理机将在进程间过于频繁切换，使处理机的开销增大，而真正用于运行用户进程的时间将减少。因此时间片的大小应选择适当。

时间片的长短通常由以下因素确定：系统的响应时间、就绪队列中的进程数目和系统的处理能力。

#### 7、多级反馈队列调度算法（MFQ）

Multilevel Feedback Queue。目前公认较好的调度算法；设置多个就绪队列并为每个队列设置不同的优先级，第一个队列优先级最高，其余依次递减。优先级越高的队列分配的时间片越短，进程到达之后按FCFS放入第一个队列，如果调度执行后没有完成，那么放到第二个队列尾部等待调度，如果第二次调度仍然没有完成，放入第三队列尾部…。只有当前一个队列为空的时候才会去调度下一个队列的进程。

### 三、 实时系统中的调度

实时系统要一个服务请求在一个确定时间内得到响应。

分为**硬实时和软实时**，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 第五章 存储管理

### 一、虚拟内存

每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。

当程序引用到一部分在物理内存中的地址空间时，由硬件立即执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

**要解决的两个问题**

**1）每个进程代码中使用的地址可能相同。解决思路：对代码中的地址重定向（加个基地址）。**

**2）物理内存可能比较小，不能同时放很多进程进来。解决思路：把要运行的代码移到内存，暂时不用的代码移入磁盘，即交换（swap），内存置换**

### 二、 连续分配方式

一个用户程序分配一个连续的内存空间
1)         单一连续分配：一个程序装入其他程序就不允许被装入。只是用于单用户单任务的OS中。

2)         固定分区分配：把内存分为若干个固定大小的区域，每个分区装入一个作业，允许并发执行。

3)         动态分区分配：根据实际需要，动态地为之分配内存空间。

4)         动态重定位分区分配：通过重定位寄存器把相对地址转化成物理地址，此转化过程是在程序执行期间，随着每条指令或数据的访问自动进行的，故称为动态重定位。

### 三、分区分配算法

1)         首次适应算法（以地址递增次序访问）

2)         循环首次适应算法（从上一次分配处开始查找）

3)         最佳适应算法（小内存到大内存依次查找）

4)         最坏适应算法（每次分配从大内存开始割让）

5)         快速适应算法（对空闲分区进行分类，并建立索引表，选最适合的控件分配给请求的进程）

对换：把暂时不运行的程序调到外存，需要时再调到内存。

地址变换机制：将用户地址空间中的逻辑地址变换为内存空间中的物理地址。

引入分段存储管理方式的目的，则主要是为了满足用户在编程和使用上多方面的要求。

段表是用于实现从逻辑段到物理内存区的映射。

### 四、分页

#### 1、基本思想

用户程序的地址空间被划分为若干固定大小的区域，称为“页”。相应地，内存空间分成若干个物理块，页和块的大小相等。可将用户程序的任一页放在内存的任一块中，实现了离散分配，由一个页表来维护它们之间的映射关系。

##### 1) 等分内存

页式存储管理将内存空间划分成**等长**的若干物理块，成为物理页面也成为物理块，每个物理块的大小一般取2的整数幂。内存的所有物理块从0开始编号，称作物理页号。

##### 2) 逻辑地址

系统将程序的逻辑空间按照**同样大小**也划分成若干页面，称为逻辑页面也称为页。程序的各个逻辑页面从0开始依次编号，称作逻辑页号或相对页号。每个页面内从0开始编址，称为页内地址。程序中的逻辑地址由两部分组成：**页号P和页内位移量W**。

在执行一个程序之前，内存管理器需要的准备工作：

1) 确定程序的页数

2) 在主存中留出足够的空闲页面

3) 将程序的所有页面载入主存里。（静态的分页，页面无需连续）

#### 2、分页存储管理的地址机构

![image-20190407150848241](/Users/ss/Documents/操作系统/分页存储地址.png)

页号x位，每个作业最多2的x次方页，页内位移量的位数表示页的大小，若页内位移量y位，则2的y次方，即页的大小，页内地址从000000000000开始到2的y次方

**若给定一个逻辑地址为A，页面大小为L，则**

**页号P=INT[A/L]，页内地址W=A  MOD  L**

#### 3、内存分配

​    相邻的页面在内存中不一定相邻，即分配给程序的内存块之间不一定连续。对程序地址空间的分页是系统自动进行的，即对用户是透明的。由于页面尺寸为2的整数次幂，故相对地址中的**高位部分即为页号**，**低位部分为页内地址**。

#### 4、页表

分页系统中，允许将进程的每一页离散地存储在内存的任一物理块中，为了能在内存中找到每个页面对应的物理块，系统为每个进程建立一张页表，用于记录进程逻辑页面与内存物理页面之间的对应关系。页表的作用是实现从**页号到物理块号的地址映射**，地址空间有多少页，该页表里就登记多少行，且按逻辑页的顺序排列，形如：

![image-20190407151349903](/Users/ss/Documents/操作系统/页表.png)

#### 5、地址变换

页式虚拟存储系统的逻辑地址是由页号和页内地址两部分组成，地址变换过程如图7-3所示。假定页面的大小为4K，图7-3中所示的十进制逻辑地址8203经过地址变换后，形成的物理地址a应为十进制。 

![image-20190407151942476](/Users/ss/Documents/操作系统/分页地址转换.png)

**页号： 8203/4096 = 2；页内偏移：8203%4096= 11；物理地址：物理块号\*页面大小+ 页内偏移= 28683。**

#### 6、具有快表的地址变换机构

分页系统中，CPU每次要存取一个数据，都要**两次访问内存**（访问页表、访问实际物理地址）。为提高地址变换速度，增设一个具有并行查询能力的特殊高速缓冲存储器，称为“联想存储器”或“快表”，存放当前访问的页表项。

快表项：页号，页架号

`基于快表的地址转换流程`按逻辑地址中的页号查快表若该页已在快表中，则由页架号和单元号形成绝对地址若该页不在快表中，则再查主存页表形成绝对地址，同时将该页登记道快表中当快表填满后，又要登记新页时，则需在快表中按一定策略淘汰一个旧登记项

#### 7、页面的共享与保护

​    当多个不同进程中需要有相同页面信息时，可以在主存中**只保留一个副本**，只要让这些进程各自的有关项中指向内存同一块号即可。同时在页表中设置相应的“存取权限”，对不同进程的访问权限进行各种必要的限制。







### 五、分段

#### 1、基本思想

页面是主存物理空间中划分出来的等长的固定区域。分页方式的优点是页长固定，因而便于构造页表、易于管理，且不存在外碎片。但分页方式的缺点是页长与程序的逻辑大小不相关。例如，某个时刻一个子程序可能有一部分在主存中，另一部分则在辅存中。这不利于编程时的独立性，并给换入换出处理、存储保护和存储共享等操作造成麻烦。

另一种划分可寻址的存储空间的方法称为分段。段是按照程序的自然分界划分的长度可以动态改变的区域。通常，程序员把子程序、操作数和常数等不同类型的数据划分到不同的段中，并且每个程序可以有多个相同类型的段。

 **段表本身也是一个段，可以存在辅存中，但一般是驻留在主存中**。段表保存中进程的PCB中

将用户程序地址空间分成若干个大小不等的段，每段可以定义一组相对完整的逻辑信息。存储分配时，以段为单位，段与段在内存中可以不相邻接，也实现了离散分配。

#### 2、分段地址结构

作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息。例程序段、数据段等。每个段都从0开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因而各段长度不等。整个作业的地址空间是**二维**的。

在段式虚拟存储系统中，虚拟地址由段号和段内地址组成，虚拟地址到实存地址的变换通过段表来实现。每个程序设置一个段表，段表的每一个表项对应一个段，每个表项至少包括三个字段：有效位（指明该段是否已经调入主存）、段起址(该段在实存中的首地址)和段长（记录该段的实际长度）。

#### 3、地址变换

针对每一个虚拟地址，存储管理部件首先以段号S为索引访问段表的第S个表项。若该表项的有效位为1，则将虚拟地址的段内地址D与该表项的段长字段比较；若段内地址较大则说明地址越界，将产生地址越界中断；否则，将该表项的段起址与段内地址相加，求得主存实地址并访存。如果该表项的有效位为0，则产生缺页中断，从辅存中调入该页，并修改段表。段式虚拟存储器虚实地址变换过程如图所示。

![image-20190407155316509](/Users/ss/Documents/操作系统/段表地址变换.png)

**绝对地址=根据段号找到段表中的起始地址+段内地址** (如果段内地址超过限长则产生“地址越界”程序性中断事件达到存储保护)

#### 4、 分段存储方式的优缺点

分页对程序员而言是不可见的，而分段通常对程序员而言是可见的，因而分段为组织程序和数据提供了方便。与页式虚拟存储器相比，段式虚拟存储器有许多优点：

(1)    段的逻辑独立性使其易于编译、管理、修改和保护，也便于多道程序共享。

(2)    段长可以根据需要动态改变，允许自由调度，以便有效利用主存空间。

(3)    方便编程，分段共享，分段保护，动态链接，动态增长

 因为段的长度不固定，段式虚拟存储器也有一些缺点：

(1)    主存空间分配比较麻烦。

(2)    容易在段间留下许多碎片，造成存储空间利用率降低。

(3)    由于段长不一定是2的整数次幂，因而不能简单地像分页方式那样用虚拟地址和实存地址的最低若干二进制位作为段内地址，并与段号进行直接拼接，必须用加法操作通过段起址与段内地址的求和运算得到物理地址。因此，段式存储管理比页式存储管理方式需要更多的硬件支持

#### 5、分页和分段的主要区别

1)  两者都采用**离散分配**方式，且都要通过地址应设机构来实现**地址变换**。

2) **页是信息的物理单位**，分页是为了有效的管理内存；**段是逻辑单位**，分段是为了维护信息完整性和独立性。

3) 页的大小固定且由系统决定，段的长度不固定，决定于用户编写的程序。

4) 分页的作业地址空间是一维的，而分段的作业地址空间是二维的。

### 六、段页式存储

#### 1、 段页式存储管理的基本思想

段页式存储组织是分段式和分页式结合的存储组织方法，这样可充分利用分段管理和分页管理的优点。

　  (1) 用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。

​     (2) 用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。

![image-20190407155656077](/Users/ss/Documents/操作系统/段页地址空间.png)

   (3)    逻辑地址结构。一个逻辑地址用三个参数表示：段号S；页号P；页内地址d。

（4）段表、页表、段表地址寄存器。为了进行地址转换，系统为每个作业建立一个段表，并且要为该作业段表中的每一个段建立一个页表。系统中有一个段表地址寄存器来指出作业的段表起始地址和段表长度。

![image-20190407155812038](/Users/ss/Documents/操作系统/段页存储.png)

#### 2、地址变换过程

1)   慢速地址转换过程

一个逻辑地址为：基地址x、段号s、页号p和页内地址d，求物理地址(((x)+s)+p)*2^(11)+d

![image-20190407160025152](/Users/ss/Documents/操作系统/地址变换.png)

在段页式系统中，为了便于实现地址变换，须配置一个段表[寄存器](http://baike.baidu.com/view/6159.htm)，其中存放段表始址和段表长TL。

1) 进行地址变换时，首先利用段号S，将它与段表长TL进行比较。若S<TL，表示未越界

2) 于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的[页表](http://baike.baidu.com/view/2143270.htm)始址

3) 利用[逻辑地址](http://baike.baidu.com/view/893778.htm)中的段内页号P来获得对应页的页表项位置，从中读出该页所在的物理块号b

4) 再利用块号b和页内地址来构成[物理地址](http://baike.baidu.com/view/883168.htm)。

上图示出了段页式系统中的地址变换机构。在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得[页表](http://baike.baidu.com/view/2143270.htm)始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的[物理地址](http://baike.baidu.com/view/883168.htm)；第三次访问才是真正从第二次访问所得的地址中，取出指令或数据。

显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲[寄存器](http://baike.baidu.com/view/6159.htm)。每次访问它时，都须同时利用段号和页号去检索[高速缓存](http://baike.baidu.com/view/32390.htm)，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成[物理地址](http://baike.baidu.com/view/883168.htm)；若未找到匹配表项，则仍须再三次访问内存。

#### 3、段页式存储管理的优缺点

 优点

(1) 它提供了大量的虚拟存储空间。

(2) 能有效地利用主存，为组织多道程序运行提供了方便。

缺点：

(1) 增加了硬件成本、系统的复杂性和管理上的开消。

(2) 存在着系统发生**抖动**的危险。

(3) 存在着内碎片。

(4) 还有各种表格要占用主存空间。

　段页式存储管理技术对当前的大、中型计算机系统来说，算是最通用、最灵活的一种方案。

### 七、页面置换算法

在程序运行过程中，若其所要访问的页面不在内存而需要把它们调入内存，但是内存已无空闲空间时，系统必须从内存中调出一个页面到磁盘对换区中，并且将程序所需要的页面调入内存中。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

#### 1. 最佳置换法（OPT，Optimal Replacement）

所选择的被换出的页面将是**最长时间内不再被访问**，通常可以保证获得**最低的缺页率**。是一种理论上的算法，因为无法知道一个页面多长时间会被再访问到。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1

进程运行时，先将 7,0,1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

可以看到，发生缺页中断的次数为9，页面置换的次数为6。

![image-20190407163758537](/Users/ss/Documents/操作系统/页面置换OPT.png)

#### 2. 先进先出（FIFO）

所选择换出的页面是**最先进入的页面**。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

FIFO算法还会产生当所分配的物理块数增大而页故障数不减反增的异常现象，这是由 Belady于1969年发现，故称为Belady异常，如图3-28所示。只有FIFO算法可能出现Belady 异常，而LRU和OPT算法永远不会出现Belady异常。

![image-20190407163314336](/Users/ss/Documents/操作系统/页面置换FIFO.png)

#### 3. 最近最久未使用（LRU, Least Recently Used）

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将**最近最久未使用的页面换出**。

可以用栈来实现该算法，栈中存储页面的页面号。当进程访问一个页面时，将该页面的页面号从栈移除，并将它压入栈顶，这样，最近被访问的页面的页面号总是在栈顶，而最近最久未使用的页面的页面号总是在栈底。

![image-20190407163543685](/Users/ss/Documents/操作系统/页面置换LRU.png)

LRU性能较好，但需要寄存器和栈的硬件支持。LRU是堆栈类的算法。理论上可以证明，堆栈类算法不可能出现Belady异常。FIFO算法基于队列实现，不是堆栈类算法。

#### 4. 时钟（Clock）

LRU算法的性能接近于OPT,但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体。

简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用(Not Recently Used, NRU)算法。

CLOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的CLOCK置换算法。这样，每一帧都处于以下四种情况之一：

1. 最近未被访问，也未被修改(u=0, m=0)。
2. 最近被访问，但未被修改(u=1, m=0)。
3. 最近未被访问，但被修改(u=0, m=1)。
4. 最近被访问，被修改(u=1, m=1)。


算法执行如下操作步骤：

1. 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。
2. 如果第1)步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。
3. 如果第2)步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为0。重复第1步，并且如果有必要，重复第2步。这样将可以找到供替换的帧。

改进型的CLOCK算法优于简单CLOCK算法之处在于替换时首选没有变化的页。由于修改过的页在被替换之前必须写回，因而这样做会节省时间。

### 八、多道程序度与抖动

#### 1、抖动

刚被淘汰出内存的页面，过后不久又要访问它，需要再次将其调入，而该页调入内存后不入又再次被淘汰出内存，然后又要访问它，如此反复，使得系统把大部分时间用在了页面的调进换出上，而几乎不能完成任何有效的工作，这种现象称为抖动

#### 2、多道程序度

由于虚拟存储器系统能从逻辑上扩大内存，这时，只需装入一个进程的部分程序和数据便可开始运行，故人们希望在系统中能运行更多的进程，即增加多道程序度，以提高处理机的利用率。

#### 3、产生抖动的原因

发生“抖动”的根本原因是，**同时在系统中运行的进程太多**，由此分配给每一个进程的物理块太少，不能满足进程正常运行的基本要求，致使每个进程在运行时，频繁地出现缺页，必须请求系统将所缺之页调入内存。这会使得在系统中排队等待页面调进/调出的进程数目增加。显然，对磁盘的有效访问时间也随之急剧增加，造成每个进程的大部分时间都用于页面的换进/换出，而几乎不能再去做任何有效的工作，从而导致发生处理机的利用率急剧下降并趋于0的情况。

#### 4、抖动的预防方法

- **采取局部置换策略**,即缺页时，只能在分配给自己的内存里进行置换，不允许从其他进程获取新的物理块，这样即使该进程发生抖动也不好影响其他进程。但效果不是很好，在某进程发生抖动后，他还会常去处于磁盘的io等待队列中，这会延迟其他进程区人员中断的处理时间。
- **把工作集算法融入到处理机调度中**，当调度程序发现处理机利用率低下时，它将试图从外存调入一个新作业进入内存，来改善处理机的利用率。 在融入工作集算法后，在调度程序从外存调入作业之前，必须检查每个进程在内存驻留页面是否足够多。如果都足够多，此时便可以将新作业调入内存中，反之则不调入。
- **利用“L=S”准则调节缺页率**，Denning于1980年提出了“L=S”的准则来调节多道程序度，其中L是缺页之间的平均时间，S是平均缺页服务时间，即用于置换一个页面所需的时间。如果是L远比S大，说明很少发生缺页，磁盘的能力尚未得到充分的利用；反之，如果是L比S小，则说明频繁发生缺页，缺页的速度已超过磁盘的处理能力。只有当L与S接近时，磁盘和处理机都可达到它们的最大利用率。理论和实践都已证明，利用“L=S”准则，对于调节缺页率是十分有效的。
- **选择暂停的进程**，当多道程序度偏高时，已影响到处理机的利用率，为了防止发生“抖动”，系统必须减少多道程序的数目。 此时根据某种算法选择一个进程，暂停该进程。

### 九、工作集

#### 1、工作集的引入

工作集是指在某段时间间隔 ∆ 里，进程实际要访问的页面的集合。把进程在某段时间间隔 ∆ 里，在时间 t 的工作集记为w(t,∆)，变量 ∆ 称为工作集“窗口尺寸” 。

对于给定的页面走向，如果 ∆ ＝ 10 次存储访问，在 t1时刻的工作集是 W(t1,10)=(1,2,5,6,7)，在 t2 时刻，工作集是 W(t2,10)=(3,4)

#### 2、工作集的特点

工作集的大小是变化的。
相对比较稳定的阶段和快速变化的阶段交替出现。
根据局部性原理，进程会在一段时间内相对稳定在某些页面构成的工作集上。
当局部性区域的位置改变时，工作集大小快速变化。
当工作集窗口滑过这些页面后，工作集又稳定在一个局部性阶段。
工作集精确度与窗口尺寸 ∆ 的选择有关。如果 ∆ 太小，那么它不能表示进程的局部特征；如果 ∆ 为无穷大，那么工作集合是进程执行需要的所有页面的集合。

如果页面正在使用，它就落在工作集中；如果不再使用，它将不出现在相应的工作集中。

工作集是局部性原理的近似表示。

如果能找出一个作业的各个工作集，并求出其页面数最大者，就可估计出该进程所需的物理块数。

利用工作集模型可以进行页面置换。工作集页面置换法的基本思想：找出一个不在工作集中的页面，把它淘汰。





工作集：一个进程当前正在使用的逻辑页面集合

常驻集：指在当前时刻，进程实际驻留在内存当中的页面集合。

工作集页面置换算法：追踪之前T个的引用，在之前T个内存访问的页引用是工作集，T被称为窗口大小

缺页率页面置换算法：

可变分配策略：常驻集大小可变。可采用全局页面置换的方式，当发生一个缺页中断时，被置换的页面可以是在其他进程当中，各个并发进程竞争的使用物理页面。

优缺点：性能较好，但增加了系统开销。

具体实现：可以使用缺页率算法来动态调整常驻集的大小。

缺页率：缺页次数/内存访问次数。影响缺页率的因素：页面置换算法，分配给进程的物理页面数目，页面本身的大小，程序的编写方法

一个交替的工作集计算明确的试图最小化页缺失：当缺页率高的时候——增加工作集，当缺页率低的时候——减少工作集

算法：

保持追踪缺失发生概率

       当缺失发生时，从上次页缺失起计算这个时间，tlast 是上次的页缺失的时间
    
       如果发生页缺失之间的时间是“大”的，之后减少工作集。
    
      如果tcurrent - tlast > T，之后从内存中移除所有在[tlast, tcurrent]时间内没有被引用的页。
    
      如果这个发生页缺失的时间是“小”的，之后增加工作集。
    
      如果 tcurrent - tlast <= T，之后增加缺失页到工作集中
如果分配给一个进程的物理页面太少，不能包含整个的工作集，即常驻集包含于工作集，那么进程将会造成很多的缺页中断，需要频繁地在内存与外存之间替换页面，从而使进程的运行速度变得很慢，把这种状态称为“抖动”。

产生抖动的原因：随着驻留内存的进程数目增加，分配给每个进程的物理页面数不断减小，缺页率不断上升。所以OS要选择一个适当的进程数目和进程需要的帧数，以便在并发水平和缺页率之间达到一个平衡。

## 第六章 文件管理

### **一、文件和文件系统**

现代OS几乎都是通过文件系统来组织和管理在计算机中所存储的大量程序和数据的。**文件系统的管理功能是通过把它所管理的程序和数据组织成一系列文件的方法来实现**的。而**文件则是指具有文件名的若干相关元素的集合**。**元素通常是记录，而记录是一组有意义的数据项的集合**。可以把数据组成分为数据项、记录、文件。

### **二、文件的逻辑结构**

对任何的文件，都存在以下两种形式的结构

　　① **文件的逻辑结构**，这是从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构，独立于文件的物理特性，又称为文件组织。

　　② **文件的物理结构**，又称为文件的存储结构，是指文件在外存上的存储组织形式，不仅与存储介质有关，还与外存分配方式有关。

#### 1、文件逻辑结构的类型

　　文件的逻辑结构可分为两大类，一类是有结构文件，这是指由一个以上的记录构成的文件，故把他称为记录式文件，另一类是无结构文件，这是指由字符流构成的文件，又称为流式文件。

　　① **有结构文件**，每个记录都用于描述实体集中的一个实体，各记录有着相同或不同数目的数据项，记录分为**定长记录**（文件中所有记录的长度都是相同的，所有记录中的各数据项都处在记录中相同的位置，具有相同的顺序和长度）和**变长记录**（文件中个记录的长度不相同，可能由于一个记录中所包含的数据项目并不相同）。根据用户和系统的需要，可采用多种方式来组织这些记录，如**顺序文件**（记录按照某种顺序排列所形成的文件，记录通常是定长的，能较快查找到文件中的记录），**索引文件**（记录为可变长度时，通常建立一张索引表，并为每个记录设置一个表项，加快对记录检索的速度），**索引顺序文件**（为文件建立一张索引表，为每一组记录中的第一个记录设置一个表项）。

　　② **无结构文件**，对于源程序、可执行文件、库函数等通常采用的是无结构文件形式，即流式文件，其长度以字节为单位。

#### 2、顺序文件

　　文件是记录的集合，文件中的记录可以是任意顺序的，因此，它可以按照各种不同的顺序进行排列，一般地，可归纳为以下两种情况。

　　① **串结构**，个记录之间的顺序与关键字无关，通常按照时间先后排序，最先存入的记录作为第一个记录，其次，为第二个记录，以此类推。

　　② **顺序结构**，文件中所有记录按照关键字排列，可以按照关键词长度从大到小排列。顺序结构的检索效率更高。

#### 3、索引文件

　　对于定长记录文件，可以方便的实现顺序存取和直接存取，然而，对于变长记录就很难实现。为了解决变长记录检索问题，可为变长记录文件建立一张索引表，对主文件中的每个记录，在索引表中设有一个相应的表项，用于记录该记录的长度L及指向该记录的指针（指向该记录在逻辑地址空间的首址），由于索引表示按记录键排序的，因此，**索引表本身是一个定长记录的顺序文件**。从而可以方便实现直接存取。

![image-20190407213338836](/Users/ss/Documents/操作系统/索引文件.png)

在对索引文件进行检索时，首先根据用户（程序）提供的关键字，并利用折半查找检索索引表，从中找到相应的表项，再利用该表项给出的指向记录的指针值，去访问所需的记录。每当要向索引文件中增加一个新纪录时，便须对索引表进行修改。索引表的问题在于除了有主文件外，还需要配置一张索引表，每个记录需要有一个索引项，因此提高了存储费用。

#### 4、索引顺序文件

　　其有效克服了变长记录不便于直接存取的缺点，而且所付出的代价也不算太大，它是顺序文件和索引文件相结合的产物，它**将顺序文件中的所有记录分为若干个组，为顺序文件建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的键值和指向记录的指针**

![image-20190407213536056](/Users/ss/Documents/操作系统/索引顺序文件.png)

　在对索引顺序文件进行检索时，首先利用用户（程序）所提供的关键字及某种查找算法去检索索引表，找到该记录组中的第一个记录的表项，从中得到该记录组第一个记录在主文件中的位置，然后，再利用顺序查找法去查找主文件，从中找出所要求的记录。

#### 5、直接文件

　　对于直接文件，则根据给定的记录键值，直接获得指定记录的物理地址，换言之，**记录键值本身就决定了记录的物理地址**，这种由记录键值到记录物理地址的转换被称为键值转换。

#### 6、哈希（Hash）文件

　　**利用Hash函数可将记录键值转换为相应记录的地址**，为了能实现文件存储空间的动态分配，通常由Hash函数所求得的并非是相应记录的地址，而是指向一目录表相应表目的指针，该表目的内容指向相应记录所在的物理块。

### **四、外存分配方式**

　　由于磁盘具有可直接访问的特性，故当磁盘来存放文件时，具有很大的灵活性。而文件的物理结构与外存分配方式有关，在采用连续分配方式时的文件物理结构是顺序式的文件结构，在采用链接分配方式将形成链接式文件结构，而索引分配方式将形成索引式文件结构。

#### 1、连续分配

　　连续分配要求为每个文件分配一组相邻接的盘块，一组盘块地址定义了磁盘上的一段线性地址。采用连续分配方式时，**可把逻辑文件中的记录顺序地存储到邻接的各物理盘块中，这样所形成的文件结构称为顺序文件结构**，这种分配方式保证了逻辑文件中的记录顺序与存储器中文件占用盘块的顺序的一致性。下图为连续分配方式（假设记录与盘块一样大）。

![image-20190407214007670](/Users/ss/Documents/操作系统/连续分配.png)

如同动态分配分区分配一样，随着文件建立时空间的分配和文件删除时的空间回收，将使磁盘空间被分割成许多小块，这些小块的连续去已难以存储文件，此即外存的碎片，同样，可以使用紧凑的方法，将盘上所有的文件紧靠在一起，把所有的碎片拼成一大片连续的存储空间。

　　连续分配的优点如下

　　① 顺序访问容易，访问一个占有连续空间的文件非常容易。

　　② 顺序访问速度快，因为由连续分配所装入的文件，其所占用的盘块可能是位于一条或几条相邻的磁道上，这是，磁头移动距离最少，这种对文件访问的速度使几种存储空间分配方式中最高的一种。

　　连续分配的缺点如下

　　① 要求又连续的存储空间，要为每个文件分配一段连续的存储空间，这样，便会产生许多外部碎片，严重地降低了外存空间利用率，定期紧凑会花费大量的机器时间。

　　② 必须实现知道文件的长度，事先知道文件的长度，然后根据其大小，在存储空间中找出一块其大小足够的存储区，将文件装入，对于动态增长的文件非常低效。

#### 2、链接分配

　　如果将一个逻辑文件存储到外存上，并不要求为整个文件分配一块连续的空间，而是可以将文件装到多个离散的盘块中，这样就可以消除连续分配的缺点。采用链接分配方式时，可通过在每个盘块上的链接指针，**将同属于一个文件的多个离散盘块链接成一个链表**，把这样形成的物理文件称为链接文件。链接分配采取离散分配方式，消除了外部碎片，故而显著地提高了外存空间的利用率，并且对文件的增、删、改、查十分方便。链接方式可分为隐式链接和显示链接两种形式。

　　① **隐式链接**， 在文件目录的每个目录项中，都须含有**指向链接文件第一个盘块和最后一个盘块的指针**。

![image-20190407214220915](/Users/ss/Documents/操作系统/隐式连接.png)

说明：第9个盘块指向第16个盘块，第16个盘块指向第1个盘块，第1个盘块指向第10个盘块，第10个盘块指向第25个盘块（结束块）。　　

　　隐式链接分配的主要问题在于：其只适合于顺序访问，对随机访问的效率及其低效。此外，其可靠性较差，任何一个指针出现问题，都会导致整个链的断开。可以将几个盘块组成一个簇，然后以簇为单位进行分配，会减少查找指定块的时间，但是会增加内部碎片。

② **显示链接**，把用于链接文件各物理块的指针，显式的放在内存的一张链接表中，该表在整个磁盘仅设置一张。

![image-20190407214504978](/Users/ss/Documents/操作系统/显式链接.png)

　　说明：表的序号从0开始，直至N-1，N为盘块总数，在每个表项中存放链接指针，即下一个盘块号，在该表中，凡是属于某一文件的第一个盘块号，或者说是每一条链的链首指针所对应的盘块号，均作为文件地址被填入相应的文件的FCB(File Control Block)的物理地址字段中，由于查找记录的过程是在内存中进行的，因而提**高了检索速度，减少了访问磁盘的次数**，由于分配给文件的所有盘块号都在该表中，故把该表称为文件分配表FAT（File Allocation Table）。

　　链接分配的问题如下：**不能支持高效的直接存储**（要对一个较大的文件进行直接存取，须首先在FAT中顺序地查找很多盘块号）；**FAT需要占用较大的内存空间**（由于一个文件所占用的盘块的盘块号是随机地分布在FAT中的，因而只有将整个FAT调入内存，才能保证FAT中找到一个文件的所有盘块号，当磁盘容量较大时，FAT占用的容量更大）

③ **索引分配**，事实上，在打开某个文件时，只需要把该文件占用的盘块号的编号调入内存即可，完全没有必要把整个FAT调入内存，为此，应该**将每个文件所对应的盘块号集中地放在一起**，索引分配方式就是基于这种想法所形成的一种分配方式。其为每个文件分配一个索引块（表），再把分配给该文件的所有盘块号都记录在该索引块中，因而该索引块就是一个含有许多磁盘块号的数组。在建立一个文件时，只需要在位为之建立的目录项中填上指向该索引块的指针（单级索引）。

![image-20190407214803183](/Users/ss/Documents/操作系统/索引分配.png)



说明：索引方式支持直接访问，可在索引块中找到第i个盘块，索引方式也不会产生外部碎片，当文件较大时，索引分配方式要优于链接分配方式。其主要问题在于：可能需要花费较多的外存空间，每当建立一个文件时，便须为之分配一个索引块，将分配给该文件的所有盘块号记录其中。对于小文件而言，索引块的利用率非常低。

　　当OS为一个大文件分配磁盘空间时，如果所分配的盘块的盘块号已经装满一个索引块时，OS便为该文件分配另一个索引块，用于将以后继续为之分配的盘块号记录于其中，以此类推，然后再通过链指针将各索引块按序链接起来，当文件太大时，索引块太多，效率是低效的。此时，应该为这些索引块再建立一级索引，称为第一级索引，还可再建立索引，称为第二级索引等等。称为多级索引分配。

![image-20190407214922930](/Users/ss/Documents/操作系统/二级索引.png)

说明：在二级索引分配方式下，若每个盘块的大小为1KB，每个盘块号占4个字节，则在一个索引块可以存放256个盘块号，这样，在两级索引时，最多可以包括存放文件的盘块号总数为64K(256 * 256)个盘块号，所允许文件最大长度为64MB，若盘块号为4KB，则一级索引的最大文件大小为4MB，二级索引的最大文件大小为4GB。

　　④ **混合索引分配方式**，将多种索引分配方式相结合而形成的一种分配方式，如直接地址（在索引结点中设置10个直接地址项，每项中所存放的是该文件数据所在盘块的盘块号，假如每个盘块大小为4KB，当文件不大于40KB时，可以直接从索引结点中读出该文件的全部盘号），一次间接地址（利用索引结点中的地址项来提供一次间接地址，其实质就是一级索引分配方式，在一次简直快中可存放1K个盘块号，允许最大文件为4MB），多次间接地址（当文件大于4MB + 40KB时，系统采用二次间址分配方式，其实质是两级索引分配方式，采用二次间址的最大文件大小为4GB，同理，可采用三次间接地址，允许文件最大大小为4TB）。

![image-20190407215112056](/Users/ss/Documents/操作系统/混合索引.png)

### **五、目录管理**

　　为了能够对文件实施有效的管理，必须对它们加以妥善组织，这主要是通过文件目录实现的，文件目录也是一种数据结构，用于标识系统中的文件及其物理地址，供检索时使用，对目录的管理要求如下

　　① **实现按名存取**，即用户只须向系统提供所需访问的文件的名字，便能够快速准确地找到指定文件在外存上的存储位置，这是目录管理中最基本的功能。

　　② **提高对目录检索速度**，通过合理地组织目录结构的方法，可加快对目录的检索速度，从而提高对文件的存取速度。

　　③ **文件共享**，在多用户系统中，应该允许用户共享一个文件。

　　④ **允许文件重名**，系统应允许不同用户对不同文件采用相同的名字，以便用户按照自己的习惯给文件命名和使用文件。

#### 5.1 文件控制块

　　为了能对文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构，称之为文件控制块FCB，文件管理程序可借助于文件控制块中的信息，对文件施加各种操作，文件与文件控制块一一对应，而人们把**文件控制块的有序集合称为文件目录**，一个文件控制块就是一个文件目录项。通常，**一个文件目录也可被看成是一个文件，称为目录文件**。

　　文件控制块包含基本信息、存取控制信息、使用信息。

　　① **基本信息**，包括文件名（标识一个文件的符号名，在每个系统中，每个文件都有唯一的名字，用户利用该名字进行存取）；文件物理位置（指文件在外存上的存储位置，包括存放文件的设备名、文件在外村上的起始盘块号、指示文件所占用的盘块数或字节数的文件长度）；文件逻辑结构（指示文件是流式文件还是记录式文件、记录数，文件是定长还是变长记录）；文件物理结构（指示文件是顺序文件、链式文件还是索引文件）

　　② **存取控制信息**，包括文件主的存取权限、核准用户的存取权限及一般用户的存取权限。

　　③ **使用信息**，包括文件的建立日期和时间、文件上一次修改的日期和时间及当前使用信息（这项信息包括当前已打开该文件的进程数、是否被其他进程锁住、文件在内存中是否已被修改但尚未拷贝到盘上）

#### 5.2 索引结点

　　**文件目录通常是存放在磁盘上的**，当文件很多时，文件目录可能要占用大量的盘块，在查找的过程中，先将存放目录文件的第一个盘块中的目录调入内存，然后把用户所给定的文件名和目录项中的文件名逐一对比。若未找到指定文件，则再将下一个盘块中的目录项调入内存。在检索目录文件时，只用到了文件名，仅当找到一个目录项（即其中的文件名与指定要查找的文件名相匹配）时，才需要从该目录项中读出该文件的物理地址，而其他一些对该文件进行描述的信息，在检索目录时一概不用，显然，这些信息在检索目录时不需要调入内存。为此，在有的系统中，如UNIX系统，便采用了把文件名和文件描述信息分开的方法，亦即，使文件描述信息单独形成一个称为索引结点的数据结构，简称为i结点，在文件目录中的每个目录项由文件名和指向该文件所对应的i结点的指针所构成。

#### 5.3 目录结构

　　目录结构的组织，关系到文件系统的存取速度，也关系到文件的共享性和安全性，目前常用的目录结构形式有单级目录、两级目录、多级目录。

　　① **单级目录结构**，在整个系统中只建立一张目录表，每个文件占一个目录项，目录项中含文件名、文件扩展名、文件长度、文件类型、文件物理地址、状态位（表示目录项是否空闲）等。每当要建立一个新文件时，必须先检查所有的目录项，以保证新文件名在目录中是唯一的，然后再从目录表中找到一个空白目录项，填入新文件的文件名及其他说明信息，并置状态为1，删除文件时，先从目录中找到该文件的目录项，回收该文件所占用的存储空间，然后再清除该目录项。单级目录的有点是简单并且能够实现目录管理的基本功能-按名存取，但是查找速度慢（查找一个目录项要花费较多的时间），不允许重名（在一个目录表中的所有文件，都不能与另一个文件有相同的名字，这是难以避免的），不便于实现文件共享（每一个用户都有自己的名字空间或命名习惯，因此，应该允许不同用户使用不同的文件名来访问同一个文件）

![image-20190407215743133](/Users/ss/Documents/操作系统/单级目录结构.png)

② **两级目录结构**，为每个用户建立一个单独的**用户文件目录UFD**（User File Directory），这些文件目录具有相似的结构，由用户所有文件的文件控制块组成。此外，系统中还有一个**主文件目录MFD**（Master File Directory），在主文件目录中，每个用户目录文件都占有一个目录项，其目录项包括**用户名和指向用户目录文件的指针**。

![image-20190407215843135](/Users/ss/Documents/操作系统/两级目录.png)

两级目录结构客服了单级目录的缺点，具有如下优点：**提高了检索目录的速度**（如果在主目录中有n个子目录，每个用户目录最多为m个目录项，则为查找一指定的目录项，最多只需要检索n+m个目录项）。**在不同的用户目录中，可以使用相同的文件名**（只要在用户自己的UFD中，每个文件名都是唯一的，不同用户可以有文件名相同的文件）。**不同用户还可使用不同的文件名来访问系统中同一个共享文件**。但在多个用户需要合作完成一个大任务时，不便于用户之间共享文件。

　　③ 多级目录结构，对于大型文件系统，通常采用三级或三级以上的目录结构，以提高对目录的检索速度和文件系统的性能。多级目录结构又称为树形目录结构，**主目录被称为根目录**，把**数据文件称为树叶**，**其他的目录均作为树的结点**。

![image-20190407220025480](/Users/ss/Documents/操作系统/多级目录.png)

说明：方框代表目录文件，圆圈代表数据文件，主目录中有是哪个用户总目录A、B、C，在B用户的总目录B中，又包括三个分目录F、E、D，其中每个分目录中又包含多个文件，为提高系统的灵活性，**应该允许在一个目录文件中的目录项既是作为目录文件的FCB，又是数据文件的FCB**，这一信息可用目录项中的一位来指示。如用户A总目录中，目录项A是目录文件FCB，而目录项B和D则是数据文件的FCB。

　　在树形目录结构中，从根目录到任何数据文件，都只有一条唯一的通路，在该路径上从树的根开始，把全部目录文件名和数据文件名依次用"/"连接起来，即构成该数据文件的路径名。**系统中的每个文件都有唯一的路径名**。例如，用户B访问文件J，则使用路径名/B/F/J来访问。

　　当一个文件系统含有很多级时，每访问一个文件，都要使用从树根开始直到树叶（数据文件）为止的、包含各中间节点（目录）的全路径名，这非常麻烦，可为每个进程设置一个当前目录，又称为工作目录，进程对各文件的访问都相对于当前目录而进行的。**把从当前目录开始值得数据文件为止所构成的路径名称为相对路径名**，而**把从树根开始的路径名称为绝对路径名**。

　　④ **增加和删除目录**，在树形目录结构中，用户可为自己建立UFD，并可再创建子目录，在用户要创建一个新文件时，只需要查看自己的UFD及其子目录中有无与新建文件相同的文件名，若无，便可在UFD或其某个子目录中增加一个新目录项。在树形目录中，如何删除一个目录，应该视情况而定，若要删除的目录为空，则简单地将其删除，使它在其上一级目录中所对应的目录项为空，若不为空，可采用如下方法：**不删除非空目录**（当目录不为空时，为了删除一个非空目录，必须先删除目录中所有的文件，使之称为空目录，然后再删除，如果目录中包含有子目录，则应该递归调用方式删除），**可删除非空目录**（将目录中的所有文件和子目录同时删除）。

#### 5.4 目录查询技术

　　当用户要访问一个已存在的文件时，系统首先利用用户提供的文件名对目录进行查询，找出该文件的文件控制块或对应索引结点，然后，根据FCB或索引结点中所记录的文件物理地址（盘块号），换算出文件在磁盘上的物理位置，最后，再通过磁盘驱动程序，将所需文件读入内存。目前常用的方式有**线性检索法**和**Hash方法。**

　　① **线性检索法**，其又称为顺序检索法，在树形目录中，用户提供的文件名是由多个文件分量名组成的路径名，此时须对多级目录进行查找，假定用户给定的文件路径名为/usr/ast/mbox，则查找过程如下。

说明：首先，系统应先读入第一个文件分量名usr，用它与根目录文件（或当前目录文件）中各目录项中的文件名顺序地进行比较，从中找到匹配者，并得到匹配项的索引结点号是6，再从6号索引结点中得到usr目录文件放在132号盘块中，将该盘块内容读入内存。接着，系统再将路径名中的第二个分量名ast读入，用它与放在132号盘块中的第二级目录文件中各目录项的文件名顺序进行比较，又找到匹配项，从中得到ast的目录文件放在26号索引结点中，再从26号索引结点中得知/usr/ast是存放在496号盘块中，再读入496号盘块。然后，将文件的第三个分量名mbox读入，用它与第三季目录文件/usr/ast中各目录项的文件名进行比较，最后得到/usr/ast/mbox的索引结点号为60，即在60号索引结点中存放了指定文件的物理地址，目录查询操作到此结束，如果在顺序查找过程中发现有一个文件分量名没有找到，则停止查找，并返回文件未找到信息。

![image-20190407220450179](/Users/ss/Documents/操作系统/线性检索.png)

② **Hash方法**，系统利用用户提供的文件名并将它转换为文件目录的索引值，再利用该索引值到目录中去查找，这将提高检索速度。

## 第七章 设备管理

### 磁盘调度算法

当多个进程同时请求访问磁盘时，需要进行磁盘调度来控制对磁盘的访问。磁盘调度的主要目标是使磁盘的平均寻道时间最少。

#### 1. 先来先服务（FCFS, First Come First Serverd）

根据进程请求访问磁盘的先后次序来进行调度。优点是公平和简单，缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

#### 2. 最短寻道时间优先（SSTF, Shortest Seek Time First）

要求访问的磁道与当前磁头所在磁道距离最近的优先进行调度。这种算法并不能保证平均寻道时间最短，但是比 FCFS 好很多。

#### 3. 扫描算法（SCAN）

SSTF 会出现进行饥饿现象。考虑以下情况，新进程请求访问的磁道与磁头所在磁道的距离总是比一个在等待的进程来的近，那么等待的进程会一直等待下去。

SCAN 算法在 SSTF 算法之上考虑了磁头的移动方向，要求所请求访问的磁道在磁头当前移动方向上才能够得到调度。因为考虑了移动方向，那么一个进程请求访问的磁道一定会得到调度。

当一个磁头自里向外移动时，移到最外侧会改变移动方向为自外向里，这种移动的规律类似于电梯的运行，因此又常称 SCAN 算法为电梯调度算法。

#### 4. 循环扫描算法（CSCAN）

CSCAN 对 SCAN 进行了改动，要求磁头始终沿着一个方向移动